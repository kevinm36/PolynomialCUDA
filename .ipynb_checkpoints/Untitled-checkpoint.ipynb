{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "from numba import float32,int32,int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pylab import has clobbered these variables: ['int64', 'float32', 'int32']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "N = 1024\n",
    "gpu_res = 0\n",
    "a = ones(N)\n",
    "b = ones(N)\n",
    "dotKernel(gpu_res,a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "TPB = 32\n",
    "N = 1024\n",
    "d_res = 0\n",
    "@cuda.jit('void(int64,int64[:],int64[:])')\n",
    "def dotKernel(d_res,d_a,d_b):\n",
    "    \n",
    "    \n",
    "    bw = cuda.blockDim.x\n",
    "    idx = cuda.threadIdx.x + cuda.blockDim.x * cuda.blockIdx.x\n",
    "\n",
    "    s_idx = cuda.threadIdx.x\n",
    "    \n",
    "    s_prod = cuda.shared.array(shape = TPB,dtype =int64)\n",
    "    s_prod[s_idx] = d_a[idx] * d_b[idx]\n",
    "    cuda.syncthreads()\n",
    "    \n",
    "    #if (s_idx == 0):\n",
    "    blockSum = 0\n",
    "    for j in range(bw):\n",
    "        blockSum += s_prod[s_idx]\n",
    "\n",
    "    #cuda.atomic.add(d_res,blockSum)\n",
    "    d_res += blockSum\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\numba\\cuda\\decorators.py:107: UserWarning: autojit is deprecated and will be removed in a future release. Use jit instead.\n",
      "  warn('autojit is deprecated and will be removed in a future release. Use jit instead.')\n"
     ]
    }
   ],
   "source": [
    "@cuda.jit('int32(float64, float64, int32)', device=True)\n",
    "def mandel(x, y, max_iters):\n",
    "    \"\"\"\n",
    "    Given the real and imaginary parts of a complex number,\n",
    "    determine if it is a candidate for membership in the Mandelbrot\n",
    "    set given a fixed number of iterations.\n",
    "    \"\"\"\n",
    "    c = complex(x, y)\n",
    "    z = complex(0, 0)\n",
    "    for i in range(max_iters):\n",
    "        z = z*z + c\n",
    "        if z.real * z.real + z.imag * z.imag >= 4:\n",
    "            return i\n",
    "    return 255\n",
    "\n",
    "@cuda.autojit\n",
    "def create_fractal(min_x, max_x, min_y, max_y, image, iters):\n",
    "    height = image.shape[0]\n",
    "    width = image.shape[1]\n",
    " \n",
    "    pixel_size_x = (max_x - min_x) / width\n",
    "    pixel_size_y = (max_y - min_y) / height\n",
    "    for x in range(width):\n",
    "        real = min_x + x * pixel_size_x\n",
    "        for y in range(height):\n",
    "            imag = min_y + y * pixel_size_y\n",
    "            color = mandel(real, imag, iters)\n",
    "            image[y, x] = color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "image = np.zeros((100, 100), dtype=np.uint8)\n",
    "create_fractal(-2.0, 1.0, -1.0, 1.0, image, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<weakproxy at 000000000A05C728 to Device at 000000000A0F2EB8>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda.select_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def matmul(A, B, C):\n",
    "    \"\"\"Perform square matrix multiplication of C = A * B\n",
    "    \"\"\"\n",
    "    i, j = cuda.grid(2)\n",
    "    if i < C.shape[0] and j < C.shape[1]:\n",
    "        tmp = 0.\n",
    "        for k in range(A.shape[1]):\n",
    "            tmp += A[i, k] * B[k, j]\n",
    "        C[i, j] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A = np.random.rand(10,10)\n",
    "B = np.random.rand(10,10)\n",
    "C = np.zeros([10,10])\n",
    "griddim = 1\n",
    "blockdim = 10\n",
    "matmul[griddim,blockdim](A,B,C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.05569361,  0.31891184,  0.02119827,  0.34066984,  0.523083  ,\n",
       "         0.11828131,  0.47566831,  0.45399405,  0.49504407,  0.21590379],\n",
       "       [ 0.21728661,  0.05547052,  0.09887185,  0.27963839,  0.0054043 ,\n",
       "         0.75343157,  0.04429046,  0.3586107 ,  0.39104793,  0.4843393 ],\n",
       "       [ 0.10798866,  0.4079104 ,  0.08335702,  0.59735901,  0.77583604,\n",
       "         0.65201966,  0.2735375 ,  0.59555094,  0.0214579 ,  0.10448313],\n",
       "       [ 0.0542797 ,  0.12234489,  0.19965953,  0.16907075,  0.44277902,\n",
       "         0.67205745,  0.00128287,  0.21935872,  0.09338792,  0.01121087],\n",
       "       [ 0.22208475,  0.37041696,  0.11514023,  0.41451599,  0.123708  ,\n",
       "         0.05621587,  0.01277507,  0.42413899,  0.71561049,  0.51176432],\n",
       "       [ 0.30097146,  0.24390718,  0.13322169,  0.08636955,  0.27358748,\n",
       "         0.26338679,  0.02575112,  0.51787332,  0.37039584,  0.18364011],\n",
       "       [ 0.33273699,  0.24454613,  0.64586645,  0.64715779,  0.04990949,\n",
       "         0.14027507,  0.21066158,  0.05503497,  0.51632086,  0.08122626],\n",
       "       [ 0.07718961,  0.23627616,  0.75662086,  0.02594269,  0.01714408,\n",
       "         0.0482026 ,  0.32569491,  0.10121471,  0.12732517,  0.55561233],\n",
       "       [ 0.42450021,  0.11520063,  0.46078532,  0.06061727,  0.32401594,\n",
       "         0.03516596,  0.20139733,  0.11184047,  0.34360932,  0.12399923],\n",
       "       [ 0.50744673,  0.30004498,  0.00743431,  0.05507304,  0.00411686,\n",
       "         0.47017508,  0.44915976,  0.36401279,  0.25087894,  0.32480734]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A*B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.05569361,  0.31891184,  0.02119827,  0.34066984,  0.523083  ,\n",
       "         0.11828131,  0.47566831,  0.45399405,  0.49504407,  0.21590379],\n",
       "       [ 0.21728661,  0.05547052,  0.09887185,  0.27963839,  0.0054043 ,\n",
       "         0.75343157,  0.04429046,  0.3586107 ,  0.39104793,  0.4843393 ],\n",
       "       [ 0.10798866,  0.4079104 ,  0.08335702,  0.59735901,  0.77583604,\n",
       "         0.65201966,  0.2735375 ,  0.59555094,  0.0214579 ,  0.10448313],\n",
       "       [ 0.0542797 ,  0.12234489,  0.19965953,  0.16907075,  0.44277902,\n",
       "         0.67205745,  0.00128287,  0.21935872,  0.09338792,  0.01121087],\n",
       "       [ 0.22208475,  0.37041696,  0.11514023,  0.41451599,  0.123708  ,\n",
       "         0.05621587,  0.01277507,  0.42413899,  0.71561049,  0.51176432],\n",
       "       [ 0.30097146,  0.24390718,  0.13322169,  0.08636955,  0.27358748,\n",
       "         0.26338679,  0.02575112,  0.51787332,  0.37039584,  0.18364011],\n",
       "       [ 0.33273699,  0.24454613,  0.64586645,  0.64715779,  0.04990949,\n",
       "         0.14027507,  0.21066158,  0.05503497,  0.51632086,  0.08122626],\n",
       "       [ 0.07718961,  0.23627616,  0.75662086,  0.02594269,  0.01714408,\n",
       "         0.0482026 ,  0.32569491,  0.10121471,  0.12732517,  0.55561233],\n",
       "       [ 0.42450021,  0.11520063,  0.46078532,  0.06061727,  0.32401594,\n",
       "         0.03516596,  0.20139733,  0.11184047,  0.34360932,  0.12399923],\n",
       "       [ 0.50744673,  0.30004498,  0.00743431,  0.05507304,  0.00411686,\n",
       "         0.47017508,  0.44915976,  0.36401279,  0.25087894,  0.32480734]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A*B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.48516786,  3.32890875,  2.55585927,  2.38882994,  3.91430149,\n",
       "         3.21107991,  2.48379384,  1.87325697,  0.        ,  0.        ],\n",
       "       [ 2.42383531,  1.90374652,  2.19794027,  1.9517842 ,  2.99950206,\n",
       "         1.71460413,  1.46773967,  1.37396405,  0.        ,  0.        ],\n",
       "       [ 2.51525363,  2.48382412,  3.12390388,  2.14617115,  3.9720185 ,\n",
       "         3.26267949,  1.7242481 ,  2.18649553,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TPB = 64\n",
    "@cuda.jit('void(float32[:],float32[:],float32[:])')\n",
    "def dot(a,b,c):\n",
    "    #idx = cuda.threadIdx.x + cuda.blockDim.x * cuda.blockIdx.x\n",
    "    i = cuda.grid(1)\n",
    "    c[i] = 10\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "griddim = 1, 2\n",
    "blockdim = 3, 4\n",
    "a = np.ones(100)\n",
    "b = np.ones(100)\n",
    "c = np.zeros(100)\n",
    "dot[griddim,blockdim](a,b,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  5.39824125e-315,   5.39824125e-315,   5.39824125e-315,\n",
       "         0.00000000e+000,   0.00000000e+000,   0.00000000e+000,\n",
       "         0.00000000e+000,   0.00000000e+000,   0.00000000e+000,\n",
       "         0.00000000e+000,   0.00000000e+000,   0.00000000e+000,\n",
       "         0.00000000e+000,   0.00000000e+000,   0.00000000e+000,\n",
       "         0.00000000e+000,   0.00000000e+000,   0.00000000e+000,\n",
       "         0.00000000e+000,   0.00000000e+000,   0.00000000e+000,\n",
       "         0.00000000e+000,   0.00000000e+000,   0.00000000e+000,\n",
       "         0.00000000e+000,   0.00000000e+000,   0.00000000e+000,\n",
       "         0.00000000e+000,   0.00000000e+000,   0.00000000e+000,\n",
       "         0.00000000e+000,   0.00000000e+000,   0.00000000e+000,\n",
       "         0.00000000e+000,   0.00000000e+000,   0.00000000e+000,\n",
       "         0.00000000e+000,   0.00000000e+000,   0.00000000e+000,\n",
       "         0.00000000e+000,   0.00000000e+000,   0.00000000e+000,\n",
       "         0.00000000e+000,   0.00000000e+000,   0.00000000e+000,\n",
       "         0.00000000e+000,   0.00000000e+000,   0.00000000e+000,\n",
       "         0.00000000e+000,   0.00000000e+000,   0.00000000e+000,\n",
       "         0.00000000e+000,   0.00000000e+000,   0.00000000e+000,\n",
       "         0.00000000e+000,   0.00000000e+000,   0.00000000e+000,\n",
       "         0.00000000e+000,   0.00000000e+000,   0.00000000e+000,\n",
       "         0.00000000e+000,   0.00000000e+000,   0.00000000e+000,\n",
       "         0.00000000e+000,   0.00000000e+000,   0.00000000e+000,\n",
       "         0.00000000e+000,   0.00000000e+000,   0.00000000e+000,\n",
       "         0.00000000e+000,   0.00000000e+000,   0.00000000e+000,\n",
       "         0.00000000e+000,   0.00000000e+000,   0.00000000e+000,\n",
       "         0.00000000e+000,   0.00000000e+000,   0.00000000e+000,\n",
       "         0.00000000e+000,   0.00000000e+000,   0.00000000e+000,\n",
       "         0.00000000e+000,   0.00000000e+000,   0.00000000e+000,\n",
       "         0.00000000e+000,   0.00000000e+000,   0.00000000e+000,\n",
       "         0.00000000e+000,   0.00000000e+000,   0.00000000e+000,\n",
       "         0.00000000e+000,   0.00000000e+000,   0.00000000e+000,\n",
       "         0.00000000e+000,   0.00000000e+000,   0.00000000e+000,\n",
       "         0.00000000e+000,   0.00000000e+000,   0.00000000e+000,\n",
       "         0.00000000e+000])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'an_array' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-0c9561c8b15b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mstream\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdevary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0man_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdot\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgriddim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mblockdim\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdevary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy_to_host\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0man_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'an_array' is not defined"
     ]
    }
   ],
   "source": [
    "stream = cuda.stream()\n",
    "devary = cuda.to_device(an_array, stream=stream)\n",
    "dot[griddim,blockdim](a,b,c)\n",
    "devary.copy_to_host(an_array, stream=stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numba import jit\n",
    "bpg = 50\n",
    "tpb = 32\n",
    "n = bpg * tpb\n",
    "acc = 0\n",
    "@cuda.jit('void(float32[:,:],float32[:,:],float32[:,:],float32)')\n",
    "def cu_square_matrix_mul(A, B, C,acc):\n",
    "    sA = cuda.shared.array(shape=(tpb, tpb), dtype=float32)\n",
    "    sB = cuda.shared.array(shape=(tpb, tpb), dtype=float32)\n",
    "\n",
    "    tx = cuda.threadIdx.x\n",
    "    ty = cuda.threadIdx.y\n",
    "    bx = cuda.blockIdx.x\n",
    "    by = cuda.blockIdx.y\n",
    "    bw = cuda.blockDim.x\n",
    "    bh = cuda.blockDim.y\n",
    "\n",
    "    x = tx + bx * bw\n",
    "    y = ty + by * bh\n",
    "\n",
    "    for i in range(bpg):\n",
    "        if x < n and y < n:\n",
    "            sA[ty, tx] = A[y, tx + i * tpb]\n",
    "            sB[ty, tx] = B[ty + i * tpb, x]\n",
    "\n",
    "        cuda.syncthreads()\n",
    "\n",
    "        if x < n and y < n:\n",
    "            for j in range(tpb):\n",
    "                acc += sA[ty, j] * sB[j, tx]\n",
    "\n",
    "        cuda.syncthreads()\n",
    "\n",
    "    if x < n and y < n:\n",
    "        C[y, x] = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "A = np.random.rand(10,10)\n",
    "B = np.random.rand(10,10)\n",
    "C = np.zeros([10,10])\n",
    "cu_square_matrix_mul(A,B,C,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.60683816e-314,   0.00000000e+000,   0.00000000e+000,\n",
       "          0.00000000e+000,   0.00000000e+000,   0.00000000e+000,\n",
       "          0.00000000e+000,   0.00000000e+000,   0.00000000e+000,\n",
       "          0.00000000e+000],\n",
       "       [  0.00000000e+000,   0.00000000e+000,   0.00000000e+000,\n",
       "          0.00000000e+000,   0.00000000e+000,   0.00000000e+000,\n",
       "          0.00000000e+000,   0.00000000e+000,   0.00000000e+000,\n",
       "          0.00000000e+000],\n",
       "       [  0.00000000e+000,   0.00000000e+000,   0.00000000e+000,\n",
       "          0.00000000e+000,   0.00000000e+000,   0.00000000e+000,\n",
       "          0.00000000e+000,   0.00000000e+000,   0.00000000e+000,\n",
       "          0.00000000e+000],\n",
       "       [  0.00000000e+000,   0.00000000e+000,   0.00000000e+000,\n",
       "          0.00000000e+000,   0.00000000e+000,   0.00000000e+000,\n",
       "          0.00000000e+000,   0.00000000e+000,   0.00000000e+000,\n",
       "          0.00000000e+000],\n",
       "       [  0.00000000e+000,   0.00000000e+000,   0.00000000e+000,\n",
       "          0.00000000e+000,   0.00000000e+000,   0.00000000e+000,\n",
       "          0.00000000e+000,   0.00000000e+000,   0.00000000e+000,\n",
       "          0.00000000e+000],\n",
       "       [  0.00000000e+000,   0.00000000e+000,   0.00000000e+000,\n",
       "          0.00000000e+000,   0.00000000e+000,   0.00000000e+000,\n",
       "          0.00000000e+000,   0.00000000e+000,   0.00000000e+000,\n",
       "          0.00000000e+000],\n",
       "       [  0.00000000e+000,   0.00000000e+000,   0.00000000e+000,\n",
       "          0.00000000e+000,   0.00000000e+000,   0.00000000e+000,\n",
       "          0.00000000e+000,   0.00000000e+000,   0.00000000e+000,\n",
       "          0.00000000e+000],\n",
       "       [  0.00000000e+000,   0.00000000e+000,   0.00000000e+000,\n",
       "          0.00000000e+000,   0.00000000e+000,   0.00000000e+000,\n",
       "          0.00000000e+000,   0.00000000e+000,   0.00000000e+000,\n",
       "          0.00000000e+000],\n",
       "       [  0.00000000e+000,   0.00000000e+000,   0.00000000e+000,\n",
       "          0.00000000e+000,   0.00000000e+000,   0.00000000e+000,\n",
       "          0.00000000e+000,   0.00000000e+000,   0.00000000e+000,\n",
       "          0.00000000e+000],\n",
       "       [  0.00000000e+000,   0.00000000e+000,   0.00000000e+000,\n",
       "          0.00000000e+000,   0.00000000e+000,   0.00000000e+000,\n",
       "          0.00000000e+000,   0.00000000e+000,   0.00000000e+000,\n",
       "          0.00000000e+000]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cu_square_matrix_mul(A,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numba import float32,int32,int64\n",
    "TPB = 32\n",
    "N = 1024\n",
    "Res = 0\n",
    "@cuda.jit('void(int64[:],int64[:])')\n",
    "def dotKernel(d_a,d_b):\n",
    "    \n",
    "    \n",
    "    bw = cuda.blockDim.x\n",
    "    idx = cuda.threadIdx.x + cuda.blockDim.x * cuda.blockIdx.x\n",
    "    if idx>=N: return\n",
    "    s_idx = cuda.threadIdx.x\n",
    "    \n",
    "    s_prod = cuda.shared.array(shape = TPB,dtype =int64)\n",
    "    s_prod[s_idx] = d_a[idx] * d_b[idx]\n",
    "    cuda.syncthreads()\n",
    "    \n",
    "    if (s_idx == 0):\n",
    "        blockSum = 0\n",
    "        for j in range(bw):\n",
    "            blockSum += s_prod[s_idx]\n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'c' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-9615bb7f0af5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdotKernel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'c' is not defined"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "a = ones(N)\n",
    "b = ones(N)\n",
    "\n",
    "dotKernel(c,a,b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "CudaAPIError",
     "evalue": "Call to cuLinkCreate results in UNKNOWN_CUDA_ERROR",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCudaAPIError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-4eb201f1f83e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbpg\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtpb\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;33m@\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margtypes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat32\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat32\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gpu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcu_square_matrix_mul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mB\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0msA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshared\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtpb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\numba\\cuda\\decorators.pyc\u001b[0m in \u001b[0;36mkernel_jit\u001b[1;34m(func)\u001b[0m\n\u001b[0;32m     90\u001b[0m             \u001b[1;31m# Force compilation for the current context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbind\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m                 \u001b[0mkernel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\numba\\cuda\\compiler.pyc\u001b[0m in \u001b[0;36mbind\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    363\u001b[0m         \u001b[0mForce\u001b[0m \u001b[0mbinding\u001b[0m \u001b[0mto\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0mCUDA\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m         \"\"\"\n\u001b[1;32m--> 365\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\numba\\cuda\\compiler.pyc\u001b[0m in \u001b[0;36mget\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m             \u001b[1;31m# Link\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 303\u001b[1;33m             \u001b[0mlinker\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    304\u001b[0m             \u001b[0mlinker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_ptx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mptx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinking\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\numba\\cuda\\cudadrv\\driver.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1189\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdrvapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcu_link_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m         driver.cuLinkCreate(len(raw_keys), option_keys, option_vals,\n\u001b[1;32m-> 1191\u001b[1;33m                             byref(self.handle))\n\u001b[0m\u001b[0;32m   1192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1193\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinalizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuLinkDestroy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\numba\\cuda\\cudadrv\\driver.pyc\u001b[0m in \u001b[0;36msafe_cuda_api_call\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    216\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0msafe_cuda_api_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m             \u001b[0mretcode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 218\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretcode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0msetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msafe_cuda_api_call\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\numba\\cuda\\cudadrv\\driver.pyc\u001b[0m in \u001b[0;36m_check_error\u001b[1;34m(self, fname, retcode)\u001b[0m\n\u001b[0;32m    246\u001b[0m             \u001b[0merrname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mERROR_MAP\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"UNKNOWN_CUDA_ERROR\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Call to %s results in %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 248\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mCudaAPIError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevnum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mCudaAPIError\u001b[0m: Call to cuLinkCreate results in UNKNOWN_CUDA_ERROR"
     ]
    }
   ],
   "source": [
    "bpg = 50\n",
    "tpb = 32\n",
    "n = bpg * tpb\n",
    "\n",
    "@cuda.jit(argtypes=[float32[:,:], float32[:,:], float32[:,:]], target='gpu')\n",
    "def cu_square_matrix_mul(A, B, C):\n",
    "    sA = cuda.shared.array(shape=(tpb, tpb), dtype=float32)\n",
    "    sB = cuda.shared.array(shape=(tpb, tpb), dtype=float32)\n",
    "\n",
    "    tx = cuda.threadIdx.x\n",
    "    ty = cuda.threadIdx.y\n",
    "    bx = cuda.blockIdx.x\n",
    "    by = cuda.blockIdx.y\n",
    "    bw = cuda.blockDim.x\n",
    "    bh = cuda.blockDim.y\n",
    "\n",
    "    x = tx + bx * bw\n",
    "    y = ty + by * bh\n",
    "\n",
    "    acc = 0.\n",
    "    for i in range(bpg):\n",
    "        if x < n and y < n:\n",
    "            sA[ty, tx] = A[y, tx + i * tpb]\n",
    "            sB[ty, tx] = B[ty + i * tpb, x]\n",
    "\n",
    "        cuda.syncthreads()\n",
    "\n",
    "        if x < n and y < n:\n",
    "            for j in range(tpb):\n",
    "                acc += sA[ty, j] * sB[j, tx]\n",
    "\n",
    "        cuda.syncthreads()\n",
    "\n",
    "    if x < n and y < n:\n",
    "        C[y, x] = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
